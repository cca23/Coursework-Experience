---
title: "Code"
author: "Caitlin Alano (cca23@pitt.edu)"
output: pdf_document:
  df_print: paged
date: '04/04/2022'
---

```{r, warning = FALSE, message=FALSE}
# This chunk is reserved for loading packages.
library(ISLR2)
library(glmnet)
library(leaps)
library(tree)
library(randomForest)
library(BART)
library(gbm)
library(glmnet)
```

```{r}
#reading in train.csv
train_csv <- read.csv("/Users/caitlinalano/Downloads/train.csv")
test_csv <- read.csv("/Users/caitlinalano/Downloads/test.csv")
```


```{r}
#obtain a scatterplot matrix of the data to find if any of the numeric predictors are correlated with one another

pairs(train_csv[, 3:11], lower.panel = NULL)
#print out diagnostic plots in order to find any extreme values (outliers/leverage points)

#summary statistics of training set
summary(train_csv)
#correlation matrix of numeric variables
cor(train_csv[, 3:11])

#Findings:
#From looking at the scatterplot matrix and correlation matrix, Temperature and Dew have a strong positive correlation of 0.9158 between them. It is probably best to only include one of them in the final model.
#
```

```{r}
#initially only include numeric type variables as possible predictors
train_num <- train_csv[, c(1, 3:11)]
head(train_num)
#split the train_csv data into a training and test set (70% train, 30% test)
set.seed(1)
trainIndex<- sample(c(rep(0, 0.7 * nrow(train_num)), rep(1, 0.3 * nrow(train_num))))
train <- train_num[trainIndex == 0,] 
test <- train_num[trainIndex == 1,]
```

```{r}
#best subset selection (numeric only)

p = 9 #number of predictors
regfit.full <- regsubsets(Count~., data = train, nvmax=p)
training.mat <- model.matrix(Count~., data = train, nvmax = p)
trainerr = rep(0, p)
#find training MSE for each model size
for(i in 1:p) {
  coefs <- coef(regfit.full, i)
  predictions <- training.mat[, names(coefs)] %*% coefs
  trainerr[i] = mean((predictions-train$Count)^2)
}
#plot training MSE for each model size
plot(trainerr, main = "Training MSE vs. Model Size", xlab = "Number of Predictors", ylab = "Training MSE", type = "b")

#using test data
testing.mat <- model.matrix(Count~., data = test, nvmax = p)
testerr = rep(0, p)
#find test MSE for each model size
for(i in 1:p) {
  coefs <- coef(regfit.full, i)
  predictions <- testing.mat[, names(coefs)] %*% coefs
  testerr[i] = mean((predictions-test$Count)^2)
}
#plot test MSE for each model size
plot(testerr, main = "Test MSE vs. Model Size", xlab = "Number of Predictors", ylab = "Test MSE", type = "b")

#find the model with the lowest Test MSE
which.min(testerr) #output: 6
#find the test MSE
testerr[6] # output: 208619.4

#find which variable(s) were removed from the model
coef(regfit.full, 6) #Wind, Visibility and Dew
summary(regfit.full)
```

```{r}
#ridge regression (numeric only): using cross validation 
#typically lasso is better for automated feature selection

#ridge regression
set.seed(1)
x <- model.matrix(Count~., data = train)[,-1]
y <- train$Count
grid <- 10^ seq (10, -2, length = 100)
ridge.mod <- glmnet (x, y, alpha = 0, lambda = grid)
trainX <- as.matrix(train[,2:10])
testX <- as.matrix(test[,2:10])
cv.out <- cv.glmnet(trainX, train$Count, alpha = 1)
bestlam <- cv.out$lambda.min
ridge.pred <- predict(ridge.mod, s = bestlam, newx = testX)
#calculate test MSE
mean((ridge.pred - test$Count)^2) # output: 208514.2

#finding coefficient values
out <- glmnet (x, y, alpha = 0)
ridge.coef <- predict (out , type = "coefficients", s = bestlam)[1:10, ]; ridge.coef
#note: ridge does not perform variable selection
#variable importance: largest coefficients
  #Hour and Temperature
```

```{r}
#lasso (numeric only): using cross validation 
lasso.mod <- glmnet (x, y, alpha = 1, lambda = grid)
set.seed (1)
cv.out <- cv.glmnet(trainX, train$Count, alpha = 1)
plot (cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict (lasso.mod , s = bestlam , newx = testX)
#calculate test MSE
mean ((lasso.pred - test$Count)^2) #output: 208500.9

#finding which coefficients are exactly zero
lasso.coef <- predict (lasso.mod , type = "coefficients", s = bestlam)[1:10, ]
lasso.coef
lasso.coef[lasso.coef != 0]
#found that Dew's coefficient estimate is now zero
#advantage to ridge regression is resulting sparse coefficients
#note that lasso does better in terms of lower MSE than ridge regression with less predictors and thus less variance
#variable importance:
  #Hour and Temperature are most important
```
```{r}
#trying best subsets on all variables including character type (EXCEPT for Data and ID)
head(train2)
p = 12 #number of predictors
regfit.full <- regsubsets(Count~., data = train2, nvmax=p)
training.mat <- model.matrix(Count~., data = train2, nvmax = p)
trainerr = rep(0, p)
#find training MSE for each model size
for(i in 1:p) {
  coefs <- coef(regfit.full, i)
  predictions <- training.mat[, names(coefs)] %*% coefs
  trainerr[i] = mean((predictions-train2$Count)^2)
}
#plot training MSE for each model size
plot(trainerr, main = "Training MSE vs. Model Size", xlab = "Number of Predictors", ylab = "Training MSE", type = "b")

#using test data
testing.mat <- model.matrix(Count~., data = test2, nvmax = p)
testerr = rep(0, p)
#find test MSE for each model size
for(i in 1:p) {
  coefs <- coef(regfit.full, i)
  predictions <- testing.mat[, names(coefs)] %*% coefs
  testerr[i] = mean((predictions-test2$Count)^2)
}
#plot test MSE for each model size
plot(testerr, main = "Test MSE vs. Model Size", xlab = "Number of Predictors", ylab = "Test MSE", type = "b")

#find the model with the lowest Test MSE
which.min(testerr) #output: 12
#find the test MSE
testerr[12] # output: 173011.6

#find which variable(s) were removed from the model
coef(regfit.full, 12) #Visibility and Dew
summary(regfit.full)
```


```{r}
#trying ridge regression with all variables (including character-type) EXCEPT for Date and ID
set.seed(1)
trainIndex2<- sample(c(rep(0, 0.7 * nrow(train_csv)), rep(1, 0.3 * nrow(train_csv))))
train2 <- train_csv[trainIndex2 == 0,c(1, 3:14)] 
test2 <- train_csv[trainIndex2 == 1,c(1, 3:14)]

x <- model.matrix(Count~., data = train2)[,-1]
testx <- model.matrix(Count~., data = test2)[,-1]
y <- train2$Count
grid <- 10^ seq (10, -2, length = 100)
ridge.mod <- glmnet (x, y, alpha = 0, lambda = grid)
trainX <- as.matrix(train2[,2:13])
testX <- as.matrix(test2[,2:13])
cv.out <- cv.glmnet(x, train$Count, alpha = 1)
bestlam <- cv.out$lambda.min
ridge.pred <- predict(ridge.mod, s = bestlam, newx = testx)
#calculate test MSE
mean((ridge.pred - test2$Count)^2) #output: 172482.2

#finding coefficient values
out <- glmnet (x, y, alpha = 0)
ridge.coef <- predict (out , type = "coefficients", s = bestlam)[1:15, ]; ridge.coef

#important variables : large coefficients
  #Hour, No Holiday, Functioning
```


```{r}
#trying lasso on all variables including character type (EXCEPT for Data and ID)
lasso.mod <- glmnet (x, y, alpha = 1, lambda = grid)
set.seed (1)
cv.out <- cv.glmnet(x, train2$Count, alpha = 1)
bestlam <- cv.out$lambda.min
lasso.pred <- predict (lasso.mod , s = bestlam , newx = testx)
#calculate test MSE
mean ((lasso.pred - test2$Count)^2) #output: #172865.7

#finding which coefficients are exactly zero
lasso.coef <- predict (lasso.mod , type = "coefficients", s = bestlam)[1:10, ]
lasso.coef
lasso.coef[lasso.coef != 0] 
#found that Dew's coefficient estimate is now zero
#advantage to ridge regression is resulting sparse coefficients
#note that lasso does better in terms of lower MSE than ridge regression with less predictors and thus less variance
#important variables
  #Hour, Temperature
```

```{r}
#random forests with all predictors besides DATE and ID
set.seed (1)
rf <- randomForest (Count ~ ., data = train2 , mtry = 3, importance = TRUE)
yhat.rf <- predict (rf, newdata = test2)
#calculate test MSE
mean ((yhat.rf - test2$Count)^2) # output: 47374.86 (significantly lower than all other methods!)
#most important variables
importance(rf) #Hour and Functioning contribute the most to MSE
```

```{r}
#subset dataframe to not include Date and ID as predictors
testpred <- test_csv[,2:13]
```

```{r}
#making columns for csv output file
ID <- test_csv[,14] # unique identifier from test dataset
Count <- predict(rf, newdata = testpred) #predicted bike rental counts
student_id <- rep(4341400, nrow(test_csv)) # my 7-digit PeopleSoft ID
predictions.df <- data.frame(ID, Count, student_id) # putting columns into a dataframe
#write dataframe to a csv file called testing_predictions_4341400.csv
write.csv(predictions.df,"/Users/caitlinalano/Downloads/testing_predictions_4341400.csv", row.names = FALSE)
```